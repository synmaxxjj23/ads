# -*- coding: utf-8 -*-
"""RandomForest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AWUaguePkbB7KNpMu_bIks0amYeJ7QZ8
"""

####   Loading Modules/Packages :: Necessary Libraries
import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report,accuracy_score

import seaborn as sns
import matplotlib.pyplot as plt

# Load and display top 2 records of the Soybean dataset
df=pd.read_csv("/content/Loandata.csv")

# DATA EXPLORATION

print(df.info())
#print(df.head(2))

#DROP LOAN ID - NOT USEFUL IN ANALYSIS
df.drop(labels='Loan_ID', axis=1, inplace=True)

#REPLACE DEPENDENTS COUNT 3+ to 3
df['Dependents'] = df['Dependents'].replace('3+', '3')

#Missing Values Management

print("Before :: MISSING VALUE COUNT\n",df.isna().sum())

df['Gender'].fillna(df['Gender'].mode()[0],inplace=True)
df['Married'].fillna(df['Married'].mode()[0],inplace=True)
df['Dependents'].fillna(df['Dependents'].mode()[0],inplace=True)
df['Education'].fillna(df['Education'].mode()[0],inplace=True)
df['Self_Employed'].fillna(df['Self_Employed'].mode()[0],inplace=True)
df['Property_Area'].fillna(df['Property_Area'].mode()[0],inplace=True)
df['Loan_Status'].fillna(df['Loan_Status'].mode()[0],inplace=True)
df['Credit_History'].fillna(df['Credit_History'].mode()[0],inplace=True)

### FILL WITH MEAN
df['LoanAmount'].fillna(df['LoanAmount'].mean(),inplace=True)
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mean(),inplace=True)

print("After :: MISSING VALUE COUNT\n",df.isna().sum())

# Handling Duplicate Values
#Verify Duplicate Values/records


print("BEFORE DROP :: DATA SIZE", df.shape)

df.drop_duplicates(keep="first",inplace=True)

#Verify Duplicate Values/records
print("AFTER DROP :: DATA SIZE", df.shape)

# Handling Outliers

#NOTE:: DATA HAS OUTLIERS BUT THEY ARE VALID RESPONSES , HENCE WE ARE NOT DROPPING THE OUTLIERS.

#verify Outliers

#Plotting the box plot
plt.figure(figsize=(20, 8))
sns.boxplot(data=df, orient="v", palette="Set2")
plt.title("Box Plot of Soybean Dataset Features")
plt.show()

#DATA TRANSORMATION
# Initialize the LabelEncoder
label_encoder = LabelEncoder()

print(df['Loan_Status'].value_counts())

# Fit and transform the columns
df['Gender'] = label_encoder.fit_transform(df['Gender'])
df['Married'] = label_encoder.fit_transform(df['Married'])
df['Education'] = label_encoder.fit_transform(df['Education'])
df['Self_Employed'] = label_encoder.fit_transform(df['Self_Employed'])
df['Property_Area'] = label_encoder.fit_transform(df['Property_Area'])
df['Loan_Status'] = label_encoder.fit_transform(df['Loan_Status'])

print(df['Loan_Status'].value_counts())

df.to_csv('CleanFile.csv', index=False)

### MACHINE LEANING MODEL DESIGN AND EVALUATION

#Feature Set
X= df.iloc[:, :-1] #"Input Features

#Target Variable/ Classs variable
Y=df.iloc[:, [-1]]

# print("Input Features (X) : \n" , X)
# print("Target Variable/Class Variable (Y) : \n" , Y)

# Split data into train and test sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Ensure Y_train and Y_test are 1D arrays
Y_train = np.array(Y_train).ravel()
Y_test = np.array(Y_test).ravel()

# Train a Random Forest Classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, Y_train)


# Train the model
# Y_train array Should be flatten into a 1D array
clf.fit(X_train, Y_train)

# Predict on the test data
Y_pred = clf.predict(X_test)

# Print accuracy
accuracy = accuracy_score(Y_test, Y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Print detailed classification report
report = classification_report(Y_test, Y_pred)
print("Classification Report:")
print(report)

#Predict the class of the new observation
new_observation= pd.DataFrame([[1,1,0,1,0,2583,2358.0,120.0,360.0,1.0,2]], columns=X.columns)

predicted_class = clf.predict(new_observation)

#### 0 - NO 1 - YES
if (predicted_class[0]=='0') :
  classLable="No"
else:
    classLable="Yes"

print("Predicted Class of NEW OBSERVATION :: ",classLable)